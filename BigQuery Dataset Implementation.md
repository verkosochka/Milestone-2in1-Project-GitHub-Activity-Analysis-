# BigQuery Dataset Implementation
---
# Table of Contents

1. GitHub Analysis BigQuery Dataset Implementation.
	-   DataBase `github_repos` dictionary (for used tables only).
		- Fields in the `languages` Table.
		- Fields in the `licenses` Table. 
		- Fields in the `files` Table. 
		- Fields in the `commits` Table.
	- Complete SQL query code for calculating product metrics (performance metrics and user activity analysis on GitHub) based on the original database.
		- Data Structure.
		- Additional Derived Features.
	- Complete SQL query code for filtering each column where the values are not NULL, to create a new consolidated table with 30,000 rows, based on the table generated by SQL query (1).
2. `Python` Dataset for BI-systems Vizualization.
3. Conclusions and Key Points.

---

# GitHub Analysis BigQuery Dataset Implementation

```SQL``` query documentation for generating a unique dataset with product metrics and calculated indicators that track developer activity and behavior on a version control web hosting platform using Git — **GitHub**.

The original full database is a [BigQuery public dataset  |  Google Cloud](https://cloud.google.com/bigquery/public-data) from Cloud Marketplace: [GitHub Activity Data](https://console.cloud.google.com/marketplace/product/github/github-repos?invt=Abt4TA&authuser=1&project=github-analysis-455609). You can refer to the full documentation of the structure for each table in the database by expanding it in BigQuery, and this notebook is designed for a complete analysis of the consolidated single table created based on the attributes of the entity model of this database.

## DataBase `github_repos` dictionary (for used tables only)

There were joined 4 tables: `languages`, `licenses`, `files`, `commits`. 
### **Fields in the `languages` Table:**

1. **`repo_name`** (STRING, Nullable):
    
    - This field contains the name of the repository where the language data is coming from. It helps identify which repository each language is associated with.
        
2. **`language`** (RECORD, Repeated):
    
    - This is a nested structure that contains detailed information about the languages used in the repository. The **`REPEATED`** mode means there can be multiple languages for a single repository.
        
    - **Fields within `language`**:
        
        - **`name`** (STRING, Nullable): The name of the programming language (e.g., Python, JavaScript, C++) used in the repository.
            
        - **`bytes`** (INTEGER, Nullable): The number of bytes used by the code written in that particular language. This indicates the proportion of the repository's code written in each language.

### **Fields in the `licenses` Table:**

1. **`repo_name`** (STRING, Nullable):
    
    - This field contains the name of the repository associated with the license. It allows you to identify which repository the license is applied to.
        
2. **`license`** (STRING, Nullable):
    
    - This field contains the type of license applied to the repository (e.g., MIT, GPL-3.0, Apache-2.0). It indicates how the code in the repository can be used, modified, and distributed.

### **Fields in the `files` Table:**

1. **`repo_name`** (STRING, Nullable):
    
    - The name of the repository where the file resides. This can be used to link the file data with specific repositories.
        
2. **`ref`** (STRING, Nullable):
    
    - A reference to a specific Git reference (e.g., branch or commit) that the file is associated with. This helps identify which version of the repository the file belongs to.
        
3. **`path`** (STRING, Nullable):
    
    - The file path within the repository. This field shows where the file is located, including directories and subdirectories.
        
4. **`mode`** (INTEGER, Nullable):
    
    - The file mode, typically indicating the file permissions or type (e.g., whether it's a regular file, a directory, or a symbolic link). This is often represented as an integer code based on file system permissions.
        
5. **`id`** (STRING, Nullable):
    
    - A unique identifier for the file. This can be used to track specific files across different versions or repositories.
        
6. **`symlink_target`** (STRING, Nullable):
    
    - If the file is a symbolic link, this field contains the target path that the symlink points to. It helps in identifying the actual file or directory that the symlink references.

### **Fields in the `commits` Table:**

1. **`commit`**: The unique identifier for the commit (string).
    
2. **`tree`**: The commit's tree, indicating the structure of the repository (string).
    
3. **`parent`**: Previous commit(s) in the history (repeated field of strings).
    
4. **`author`**: Information about the commit's author:
    
    - `name` (string)
        
    - `email` (string)
        
    - `time_sec` (integer, timestamp of commit)
        
    - `tz_offset` (integer, timezone offset)
        
    - `date` (record with `seconds` and `nanos` as time components).
        
5. **`committer`**: Information about the person who committed the change:
    
    - `name` (string)
        
    - `email` (string)
        
    - `time_sec` (integer)
        
    - `tz_offset` (integer).
        
6. **`subject`**: The subject line of the commit message (string).
    
7. **`message`**: The full commit message (string).
    
8. **`trailer`**: Additional commit metadata in key-value pairs (repeated records):
    
    - `key` (string)
        
    - `value` (string)
        
    - `email` (string).
        
9. **`difference`**: Changes made in the commit (repeated records):
    
    - `old_mode`, `new_mode`: File mode changes (integer).
        
    - `old_path`, `new_path`: Changes to file paths (string).
        
    - `old_sha1`, `new_sha1`: The old and new commit hashes for files (string).
        
    - `old_repo`, `new_repo`: Repository changes (string).
        
    - `difference_truncated`: Boolean flag to indicate truncation in differences.
        
    - `repo_name`: The repository name (repeated string).
        
    - `encoding`: File encoding used (string).

This file contains queries for both **the full original database** and **the generated dataset (sample)**, which will be used for all subsequent operations such as data cleaning, data aggregation, data augmentation, statistical hypothesis testing, and the development of both static and interactive visualizations. 

This dataset provides a comprehensive overview of GitHub repositories, offering detailed insights into their activity and technical makeup. By analyzing it, organizations can better understand the dynamics of open-source projects, identify active communities, and make informed decisions about project management and technology choices.

---

## Complete SQL query code for calculating product metrics (performance metrics and user activity analysis on GitHub) based on the original database:

```SQL
CREATE OR REPLACE TABLE `github-analysis-455609.github_activity_analysis.github_activity_analysis` AS

WITH lang AS (
  SELECT
    repo_name,
    l.name AS language,
    l.bytes AS language_bytes
  FROM `bigquery-public-data.github_repos.languages`,
  UNNEST(language) AS l
),

top_lang AS (
  SELECT *
  FROM (
    SELECT
      repo_name,
      l.name AS top_language,
      l.bytes AS top_language_bytes,
      ROW_NUMBER() OVER (PARTITION BY repo_name ORDER BY l.bytes DESC) AS rnk
    FROM `bigquery-public-data.github_repos.languages`,
    UNNEST(language) AS l
  )
  WHERE rnk = 1
),

license AS (
  SELECT
    repo_name,
    license
  FROM `bigquery-public-data.github_repos.licenses`
),

file_count AS (
  SELECT
    repo_name,
    COUNT(*) AS total_files
  FROM `bigquery-public-data.github_repos.files`
  GROUP BY repo_name
),

commit_count AS (
  SELECT
    c.repo_name[OFFSET(0)] AS repo,
    COUNT(*) AS total_commits
  FROM `bigquery-public-data.github_repos.commits` c
  WHERE ARRAY_LENGTH(c.repo_name) > 0
  GROUP BY repo
),

lang_count AS (
  SELECT
    repo_name,
    COUNT(*) AS used_languages
  FROM `bigquery-public-data.github_repos.languages`,
  UNNEST(language) AS l
  GROUP BY repo_name
)

SELECT
  lang.repo_name,
  lang.language,
  lang.language_bytes,
  license.license,
  file_count.total_files,
  commit_count.total_commits,
  lang_count.used_languages,
  top_lang.top_language,
  ROUND(SAFE_DIVIDE(lang.language_bytes, NULLIF(file_count.total_files, 0)), 2) AS avg_bytes_per_file,
  ROUND(SAFE_DIVIDE(commit_count.total_commits, NULLIF(file_count.total_files, 0)), 2) AS avg_commits_per_file,
  SAFE_DIVIDE(commit_count.total_commits, NULLIF(lang.language_bytes, 0)) AS commit_instensity_score,
  SAFE_DIVIDE(file_count.total_files, NULLIF(lang_count.used_languages, 0)) AS avg_files_per_lang,
  SAFE_DIVIDE(lang.language_bytes, SUM(lang.language_bytes) OVER (PARTITION BY lang.repo_name)) AS code_density,
  SAFE_DIVIDE(commit_count.total_commits, NULLIF(lang_count.used_languages, 0)) AS avg_commits_per_lang
FROM lang
LEFT JOIN license ON lang.repo_name = license.repo_name
LEFT JOIN file_count ON lang.repo_name = file_count.repo_name
LEFT JOIN commit_count ON lang.repo_name = commit_count.repo
LEFT JOIN lang_count ON lang.repo_name = lang_count.repo_name
LEFT JOIN top_lang ON lang.repo_name = top_lang.repo_name
```

As the result of this SQL-query we have the following documentation:
#### Data Structure:

The dataset consists of the following columns:

1. **`repo_name`** (STRING, Nullable):
    
    - **Description:** The name of the repository.
        
    - **Example:** `"tensorflow/tensorflow"`, `"microsoft/vscode"`
        
2. **`language`** (STRING, Nullable):
    
    - **Description:** The programming language used in the repository (this can represent the language for a specific file or general project use).
        
    - **Example:** `"Python"`, `"JavaScript"`
        
3. **`language_bytes`** (INTEGER, Nullable):
    
    - **Description:** The total number of bytes of code in the repository that is written in the specified `language`. Represents the size of the code base in terms of bytes.
        
    - **Example:** `250000`, `134500`

**!NOTE**: In the following sections (`code shells` in the **data struct list**), the code will exclusively demonstrate the process of obtaining features and their calculation methods, as well as indicating from which database table the initial metric or indicator was taken. **Running this subquery separately from the main query builder will not provide the corresponding output**. The subquery should be adapted as a standalone query if you are specifically interested in one of the listed metrics. Additionally, we do not apply rounding directly through SQL, as each metric requires individual attention and appropriate precision for proper distribution analysis and statistical tests (this is covered in the *Jupyter Notebook*).

SQL subquery for the following features `repo_name`, `language`, `language_bytes` :
```SQL subquery for the following features
lang AS (
  SELECT
    repo_name,
    l.name AS language,
    l.bytes AS language_bytes
  FROM `bigquery-public-data.github_repos.languages`,
  UNNEST(language) AS l
)
```

4. **`license`** (STRING, Nullable):
    
    - **Description:** The license type for the repository, which governs the legal terms for usage and distribution of the code.
        
    - **Example:** `"MIT"`, `"GPL-3.0"`
```SQL
license AS (
  SELECT
    repo_name,
    license
  FROM `bigquery-public-data.github_repos.licenses`
)
```

5. **`total_files`** (INTEGER, Nullable):
    
    - **Description:** The total number of files in the repository.
        
    - **Example:** `150`, `320`
```SQL
file_count AS (
  SELECT
    repo_name,
    COUNT(*) AS total_files
  FROM `bigquery-public-data.github_repos.files`
  GROUP BY repo_name
)
```
6. **`total_commits`** (INTEGER, Nullable):
    
    - **Description:** The total number of commits made to the repository.
        
    - **Example:** `1200`, `8000`
```SQL
commit_count AS (
  SELECT
    c.repo_name[OFFSET(0)] AS repo,
    COUNT(*) AS total_commits
  FROM `bigquery-public-data.github_repos.commits` c
  WHERE ARRAY_LENGTH(c.repo_name) > 0
  GROUP BY repo
)
```
7. **`used_languages`** (INTEGER, Nullable):
    
    - **Description:** The number of distinct programming languages used in the repository.
        
    - **Example:** `2`, `3`
```SQL
lang_count AS (
  SELECT
    repo_name,
    COUNT(*) AS used_languages
  FROM `bigquery-public-data.github_repos.languages`,
  UNNEST(language) AS l
  GROUP BY repo_name
)
```
8. **`top_language`** (STRING, Nullable):
    
    - **Description:** The primary or most used programming language in the repository.
        
    - **Example:** `"Python"`, `"JavaScript"`
```SQL
top_lang AS (
  SELECT *
  FROM (
    SELECT
      repo_name,
      l.name AS top_language,
      l.bytes AS top_language_bytes,
      ROW_NUMBER() OVER (PARTITION BY repo_name ORDER BY l.bytes DESC) AS rnk
    FROM `bigquery-public-data.github_repos.languages`,
    UNNEST(language) AS l
  )
  WHERE rnk = 1
)
```
9. **`avg_bytes_per_file`** (FLOAT, Nullable):
    
    - **Description:** The average size of files in the repository, calculated as the total size (in bytes) divided by the number of files.
        
    - **Formula:** `avg_bytes_per_file = language_bytes / total_files`
        
    - **Example:** `1700.5`, `420.75`
    
10. **`avg_commits_per_file`** (FLOAT, Nullable):
     
	- **Description:** The average number of commits per file in the repository.
        
	- **Formula:** `avg_commits_per_file = total_commits / total_files`
	     
	- **Example:** `8.5`, `25.3`

---


#### Additional Derived Features:

The dataset also includes derived metrics to better understand the structure and activity of repositories:

1. **`commit_intensity_score`** (FLOAT, Nullable):
    
    - **Description:** A measure of commit intensity, calculated as the total number of commits divided by the total bytes of code in the repository. This metric indicates how active a repository is relative to its size.
        
    - **Formula:** `commit_intensity_score = total_commits / language_bytes`
        
    - **Example:** `0.005`, `0.03`
        
2. **`avg_files_per_lang`** (FLOAT, Nullable):
    
    - **Description:** The average number of files per programming language in the repository.
        
    - **Formula:** `avg_files_per_lang = total_files / used_languages`
        
    - **Example:** `75`, `50`
        
3. **`code_density`** (FLOAT, Nullable):
    
    - **Description:** The ratio of the bytes of code written in a specific language to the total bytes of code across all languages in the repository.
        
    - **Formula:** `code_density = language_bytes / SUM(language_bytes) OVER (PARTITION BY repo_name)`
        
    - **Example:** `0.4`, `0.6`
        
4. **`avg_commits_per_lang`** (FLOAT, Nullable):
    
    - **Description:** The average number of commits for each language used in the repository.
        
    - **Formula:** `avg_commits_per_lang = total_commits / used_languages`
        
    - **Example:** `300`, `1000`

## Complete SQL query code for filtering each column where the values are not NULL, to create a new consolidated table with 30,000 rows, based on the table generated by SQL query (1).

```SQL
CREATE OR REPLACE TABLE `github-analysis-455609.github_activity_analysis.github_activity_analysis_clean_30K` AS

SELECT 
  total_commits, 
  total_files, 
  language_bytes, 
  used_languages, 
  top_language, 
  repo_name, 
  language, 
  license, 
  avg_bytes_per_file, 
  avg_commits_per_file, 
  avg_commits_per_lang, 
  avg_files_per_lang, 
  commit_instensity_score, 
  code_density
FROM `github-analysis-455609.github_activity_analysis.github_activity_analysis`
WHERE 
  total_commits IS NOT NULL
  AND total_files IS NOT NULL
  AND language_bytes IS NOT NULL
  AND used_languages IS NOT NULL
  AND top_language IS NOT NULL
  AND repo_name IS NOT NULL
  AND language IS NOT NULL
  AND license IS NOT NULL
  AND avg_bytes_per_file IS NOT NULL
  AND avg_commits_per_file IS NOT NULL
  AND avg_commits_per_lang IS NOT NULL
  AND avg_files_per_lang IS NOT NULL
  AND commit_instensity_score IS NOT NULL
  AND code_density IS NOT NULL
ORDER BY RAND()
LIMIT 30000
```

This query is used to **clean the dataset** by filtering out rows with **NULL values** in key columns and then selecting a **random sample** of 30,000 rows. This is done in order to ensure that the dataset used for further analysis is consistent and contains only valid data. It also reduces the size of the dataset for performance optimization or more manageable analysis.

The use of **`ORDER BY RAND()`** can be computationally expensive, especially for large datasets, as it requires sorting all the rows randomly. If the dataset is too large, it may be worth considering more efficient methods of random sampling (using `TABLESAMPLE`). In **BigQuery**, **`TABLESAMPLE`** is not used in the same way as in other SQL-based systems like PostgreSQL or SQL Server. BigQuery does not support the `TABLESAMPLE` keyword as part of a query.

You can use metadata via `INFORMATION_SCHEMA` to dynamically create a conditional query to check for NULL values across all columns. Using `Python `or another scripting tool allows automating this process without the need to manually list each column.

To get the `INFORMATION_SCHEMA` use this SQL-query:

```SQL
SELECT column_name
FROM github-analysis-455609.github_activity_analysis.INFORMATION_SCHEMA.COLUMNS`
WHERE table_name = 'github_activity_analysis_clean_30K'
```

You can download the GitHub-Activity-Analysis dataset with the following link:
- .csv: [GitHub Activity Dataset](https://drive.google.com/file/d/17G7a_cQI1d5Yd_PtU0ur56ZUBuAUV9ml/view?usp=drive_link) 
- .xlsx: [GitHub Activity Dataset]( https://docs.google.com/spreadsheets/d/1qB4dKAOOidrfsKoSoPHqWu_CMnF-uT3X/edit?usp=drive_link&ouid=102100486137110097760&rtpof=true&sd=true)

# `Python` Dataset for BI-systems Vizualization

According to the [2025 Programming Language Rankings](https://www.index.dev/blog/most-popular-programming-languages-) , Python stands as the leading programming language, forming the foundation for various domains such as **web development** (Django, Flask, FastAPI), **data science & analytics** (pandas, numpy, matplotlib), **machine learning & AI** (tensorFlow, pytorch, scikit-learn), **automation & scripting** (selenium, scrapy, pyautoGUI, shell scripting), **cybersecurity & ethical hacking**, **game development** (pygame and panda3D), **embedded systems & IoT** ( micropython and circuitpython), **finance & fintech**, and **cloud & DevOps**.
 
Here is the SQL-query for creating a special dataset for Dashboard:

```sql
CREATE OR REPLACE TABLE `github-analysis-455609.github_activity_analysis.github_activity_analysis_python_30K` AS

WITH filtered_data AS (
    SELECT
      total_commits,
      total_files,
      language_bytes,
      used_languages,
      top_language,
      repo_name,
      language,
      license,
      avg_bytes_per_file,
      avg_commits_per_file,
      avg_commits_per_lang,
      avg_files_per_lang,
      commit_instensity_score,
      code_density

    FROM `github-analysis-455609.github_activity_analysis.github_activity_analysis`
    WHERE
      total_commits IS NOT NULL
      AND total_files IS NOT NULL
      AND language_bytes IS NOT NULL
      AND used_languages IS NOT NULL
      AND repo_name IS NOT NULL
      AND license IS NOT NULL
      AND avg_bytes_per_file IS NOT NULL
      AND avg_commits_per_file IS NOT NULL
      AND avg_commits_per_lang IS NOT NULL
      AND avg_files_per_lang IS NOT NULL
      AND commit_instensity_score IS NOT NULL
      AND code_density IS NOT NULL
      AND top_language = 'Python'
      AND language = 'Python'

    ORDER BY RAND()
    LIMIT 30000  
)

SELECT
  repo_name,
  language_bytes,
  license,
  total_files,
  total_commits,
  used_languages,
  avg_bytes_per_file,
  avg_commits_per_file,
  commit_instensity_score,
  avg_files_per_lang,
  code_density,
  avg_commits_per_lang,

  CASE
    WHEN used_languages = 1 THEN 'Monolingual'
    WHEN used_languages = 2 THEN 'Duolingual'
    WHEN used_languages = 3 THEN 'Trilingual'
    ELSE 'Multilingual'
  END AS language_category,

  CASE
    WHEN license IN ('unlicense', 'cc0-1.0') THEN 'Non-Open-Source'
    ELSE 'Open Source'
  END AS license_type

FROM filtered_data
;
```

First of all,  we applied limit here to reduce the data early and set the filter for getting only `Python`repositiries, where `language` and `top_language` equal to `Python`. Secondly, we created language category column (`language_category`) and license type column (`license_type`) as we've done in the previous dataset using Python packages such as pandas. 

You can download the Python-Activity-Analysis dataset with the following link:
- .csv: [Google Drive - Python Activity Dataset](https://drive.google.com/file/d/1JyxWKULUc44hSTPLwnX5UyrUofxs8QfZ/view?usp=sharing) 
- .xlsx: [Google Drive - Python Activity Dataset](https://drive.google.com/file/d/1J5yCuDyzfTDATZpu8aNNFykBAAhCSfty/view?usp=drive_link) 

Dashboard with illustrated KPIs and Insights: 
- [GitHub Activity of Python Repositories | Tableau Public](https://public.tableau.com/app/profile/veronika.kobets/viz/GitHub_Activity_Python/GitHubActivityofPythonRepositories) 

# Conclusions and Key Points
---
This dataset is primarily designed for **data analysis** and **data science** to identify trends, make predictions, and gain insights into GitHub repositories. It can be used for:

- **Understanding repository activity**. Which repositories are the most active, and how does this relate to their technical characteristics (e.g., language, file count)?
    
- **License impact**. Investigating the relationship between the type of license and the level of activity (commits, file changes).
    
- **Technology trends**. Analyzing which programming languages are associated with more active or larger repositories.
    
- **Optimizing project management**. Estimating the typical number of files, languages, and commits per repository and understanding how repository attributes affect development speed.